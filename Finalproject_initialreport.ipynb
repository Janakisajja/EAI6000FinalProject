{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Finalproject-initialreport.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Janakisajja/EAI6000FinalProject/blob/master/Finalproject_initialreport.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lpfLiugcBWwM",
        "colab_type": "text"
      },
      "source": [
        "Project Description- We are implementing Sentiment analysis using twitter data. We will fetch data from twitter and implement text segmentation using NLP. The text will be the tweets which will be divided into positive text, negative text, neutral text also, some special characters like, hashtags etc. Through this, we will analyse and differentiate between any two factors and compare both of them."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CZ-Yb7WzBbVA",
        "colab_type": "text"
      },
      "source": [
        "Team: EAI 6000 (Capstone Project)\n",
        "\n",
        "*   Shrutika Mokashi\n",
        "*   Yashmi Sevak\n",
        "*   Janaki Sajja\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FMA-yYkq_9LC",
        "colab_type": "text"
      },
      "source": [
        "For using this package, first we need to install it using pip."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dOAN2TvYlk-f",
        "colab_type": "code",
        "outputId": "b2cc806d-8921-45c7-840b-a5852be9518e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "pip install python-twitter"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: python-twitter in /usr/local/lib/python3.6/dist-packages (3.5)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from python-twitter) (0.16.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from python-twitter) (2.21.0)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.6/dist-packages (from python-twitter) (1.3.0)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->python-twitter) (2.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->python-twitter) (2019.11.28)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->python-twitter) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->python-twitter) (1.24.3)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib->python-twitter) (3.1.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0NpUMH7AD7WN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WylIzLxQ_sCd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"Contains tools for preprocess text data.\n",
        "@author scorrea\n",
        "\"\"\"\n",
        "import re\n",
        "import numpy as np\n",
        "from nltk.stem import SnowballStemmer\n",
        "\n",
        "\n",
        "SUPPPORTED_LANG_STEMMER = {\n",
        "    'SPA': SnowballStemmer('spanish'),\n",
        "    'ENG': SnowballStemmer('english'),\n",
        "    'PRT': SnowballStemmer('portuguese'),\n",
        "}\n",
        "\n",
        "\n",
        "def remove_pattern(input_txt, pattern):\n",
        "    r = re.findall(pattern, input_txt)\n",
        "    for i in r:\n",
        "        input_txt = re.sub(i, '', input_txt)\n",
        "\n",
        "    return input_txt\n",
        "\n",
        "def rm_pun_num_esp_cha(pandas_input):\n",
        "   return pandas_input.str.replace(\"[^a-zA-Z#]\", \" \")\n",
        "\n",
        "def rm_esp_cha(pandas_input):\n",
        "   return pandas_input.str.replace(\"[^a-zA-Z0-9áéíóúÁÉÍÓÚâêîôÂÊÎÔãõÃÕñçÇ: ]\", \" \")\n",
        "\n",
        "def rm_length_word(input_data, word_length=3):\n",
        "    return input_data.apply(lambda x: ' '.join([w for w in x.split() if len(w) > word_length]))\n",
        "\n",
        "def tokenize(input_data):\n",
        "    return input_data.apply(lambda x: x.split())\n",
        "\n",
        "def _check_lang(lang):\n",
        "  if lang in SUPPPORTED_LANG_STEMMER:\n",
        "        return True\n",
        "  else:\n",
        "      return False\n",
        "\n",
        "def stemmer(input_data, language='ENG'):\n",
        "    if  _check_lang(language):\n",
        "        stemmer = SUPPPORTED_LANG_STEMMER[language]\n",
        "        return input_data.apply(lambda x: [stemmer.stem(i) for i in x])\n",
        "    else:\n",
        "        raise \"Language {} not sopported for stemming\".format(language)\n",
        "\n",
        "def join_tokenize(input_data, join_char=' '):\n",
        "    return input_data.apply(lambda x: join_char.join(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lt1NYS47ANPf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5OXAeW2bDrKF",
        "colab_type": "text"
      },
      "source": [
        "We have taken the code from below link:\n",
        "\n",
        "> Indented block\n",
        "\n",
        "\n",
        "https://medium.com/@scorrea92/nlp-twitter-sentiment-analysis-with-tensorflow-15e1b2594cfa"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5qIz_7wwDS9O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ohUdCh1PDvL8",
        "colab_type": "text"
      },
      "source": [
        "Currently trying to understand how it works later so that we can start developing on our own."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sh2syofSD04U",
        "colab_type": "code",
        "outputId": "3b81ff9c-ec83-4b37-84b3-874854cf161d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import re\n",
        "train_path = 'drive/My Drive/train_E6oV3lV.csv'\n",
        "test_path = 'drive/My Drive/test_tweets_anuFYb8.csv'\n",
        "train  = pd.read_csv(train_path)\n",
        "test = pd.read_csv(test_path)\n",
        "\n",
        "all_data = train.append(test, ignore_index=True, sort=True)\n",
        "all_data['tidy_tweet'] = np.vectorize(remove_pattern)(all_data['tweet'], \"@[\\w]*\")\n",
        "all_data['tidy_tweet'] = rm_pun_num_esp_cha(all_data['tidy_tweet'])\n",
        "all_data['tidy_tweet'] = rm_length_word(all_data['tidy_tweet'])\n",
        "tokenized_tweet = tokenize(all_data['tidy_tweet'])\n",
        "\n",
        "tokenized_tweet = stemmer(tokenized_tweet)\n",
        "all_data['tidy_tweet'] = join_tokenize(tokenized_tweet)\n",
        "#all_data['hashtag'] = hashtag_extract(all_data['tidy_tweet'], flatten=False)\n",
        "all_data['tidy_tweet'] = np.vectorize(remove_pattern)(all_data['tidy_tweet'], \"#[\\w]*\")\n",
        "\n",
        "all_data[\"Name Length\"] = all_data['tidy_tweet'].str.len()\n",
        "all_data.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>label</th>\n",
              "      <th>tweet</th>\n",
              "      <th>tidy_tweet</th>\n",
              "      <th>Name Length</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>@user when a father is dysfunctional and is s...</td>\n",
              "      <td>when father dysfunct selfish drag kid into dys...</td>\n",
              "      <td>52</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
              "      <td>thank  credit caus they offer wheelchair van</td>\n",
              "      <td>46</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>bihday your majesty</td>\n",
              "      <td>bihday your majesti</td>\n",
              "      <td>19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>#model   i love u take with u all the time in ...</td>\n",
              "      <td>love take with time</td>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>factsguide: society now    #motivation</td>\n",
              "      <td>factsguid societi</td>\n",
              "      <td>18</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id  label  ...                                         tidy_tweet Name Length\n",
              "0   1    0.0  ...  when father dysfunct selfish drag kid into dys...          52\n",
              "1   2    0.0  ...     thank  credit caus they offer wheelchair van            46\n",
              "2   3    0.0  ...                                bihday your majesti          19\n",
              "3   4    0.0  ...                                love take with time          20\n",
              "4   5    0.0  ...                                 factsguid societi           18\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k_ZT6C9yD5Nq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}